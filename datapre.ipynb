{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Step 1: Data Collection and Preprocessing\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img = Image.open(os.path.join(folder_path, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "def resize_and_normalize(images, target_size=(128, 128)):\n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        img = img.resize(target_size, Image.ANTIALIAS)\n",
    "        img_array = np.array(img)\n",
    "        # Normalize pixel values to [-1, 1]\n",
    "        normalized_img = (img_array.astype(np.float32) - 127.5) / 127.5\n",
    "        processed_images.append(normalized_img)\n",
    "    return np.array(processed_images)\n",
    "\n",
    "def split_data(data, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, random_seed=42):\n",
    "    random.seed(random_seed)\n",
    "    num_samples = len(data)\n",
    "    train_size = int(train_ratio * num_samples)\n",
    "    val_size = int(val_ratio * num_samples)\n",
    "\n",
    "    random.shuffle(data)\n",
    "    train_data = data[:train_size]\n",
    "    remaining_data = data[train_size:]\n",
    "\n",
    "    val_data = remaining_data[:val_size]\n",
    "    test_data = remaining_data[val_size:]\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "raw_dataset_folder = 'cars'\n",
    "category_images = load_images_from_folder(raw_dataset_folder)\n",
    "\n",
    "# Resize and normalize the images to 128x128\n",
    "target_size = (128, 128)\n",
    "processed_images = resize_and_normalize(category_images, target_size=target_size)\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "train_data, val_data, test_data = split_data(processed_images)\n",
    "\n",
    "# Print the number of images in each set\n",
    "print(f\"Number of training images: {len(train_data)}\")\n",
    "print(f\"Number of validation images: {len(val_data)}\")\n",
    "print(f\"Number of testing images: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Step 2: Define the Generator and Discriminator Networks\n",
    "\n",
    "# Generator architecture\n",
    "def make_generator_model(noise_dim=100, target_size=(128, 128, 3)):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(256, input_dim=noise_dim))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dense(512))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dense(1024))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dense(np.prod(target_size), activation='tanh'))\n",
    "    model.add(layers.Reshape(target_size))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Discriminator architecture\n",
    "def make_discriminator_model(target_size=(128, 128, 3)):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=target_size))\n",
    "\n",
    "    model.add(layers.Dense(1024))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(layers.Dense(512))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(layers.Dense(256))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create instances of the generator and discriminator models\n",
    "generator = make_generator_model()\n",
    "discriminator = make_discriminator_model()\n",
    "\n",
    "# Print the summary of generator and discriminator models\n",
    "generator.summary()\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Step 3: Build the GAN Model\n",
    "\n",
    "def make_gan_model(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = tf.keras.Input(shape=(100,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "\n",
    "    gan = tf.keras.models.Model(gan_input, gan_output)\n",
    "    return gan\n",
    "\n",
    "# Create the GAN model\n",
    "gan = make_gan_model(generator, discriminator)\n",
    "\n",
    "# Compile the GAN (for generator training)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 4: Define Loss Functions and Implement Training Loop\n",
    "\n",
    "# Define loss functions for generator and discriminator\n",
    "def generator_loss(fake_output):\n",
    "    return tf.keras.losses.binary_crossentropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = tf.keras.losses.binary_crossentropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = tf.keras.losses.binary_crossentropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "NOISE_DIM = 100\n",
    "\n",
    "# Function to generate and save sample images during training\n",
    "def generate_and_save_images(model, epoch, test_input, save_path='gan_samples'):\n",
    "    predictions = model(test_input, training=False)\n",
    "    predictions = (predictions + 1) * 0.5  # Rescale images to [0, 1]\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i])\n",
    "        plt.axis('off')\n",
    "    plt.savefig(f'images/image_at_epoch_{epoch:04d}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Training loop\n",
    "def train_gan(generator, discriminator, gan, train_data, epochs, batch_size, noise_dim):\n",
    "    num_batches = len(train_data) // batch_size\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx in range(num_batches):\n",
    "            # Train discriminator\n",
    "            noise = np.random.normal(0, 1, size=(batch_size, noise_dim))\n",
    "            generated_images = generator.predict(noise)\n",
    "\n",
    "            real_images = train_data[batch_idx * batch_size: (batch_idx + 1) * batch_size]\n",
    "\n",
    "            real_labels = np.ones((batch_size, 1))\n",
    "            fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "            d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
    "            d_loss_fake = discriminator.train_on_batch(generated_images, fake_labels)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, size=(batch_size, noise_dim))\n",
    "            valid_labels = np.ones((batch_size, 1))\n",
    "            g_loss = gan.train_on_batch(noise, valid_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Start GAN Training and Evaluate Progress\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "NOISE_DIM = 100\n",
    "\n",
    "# Create a new instance of the generator and discriminator models\n",
    "generator = make_generator_model()\n",
    "discriminator = make_discriminator_model()\n",
    "\n",
    "# Compile the discriminator (for binary classification)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n",
    "# Create the GAN model\n",
    "gan = make_gan_model(generator, discriminator)\n",
    "\n",
    "# Compile the GAN (for generator training)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n",
    "# Step 5: Start GAN Training\n",
    "train_gan(generator, discriminator, gan, train_data, EPOCHS, BATCH_SIZE, NOISE_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate and Fine-Tune (Optional)\n",
    "\n",
    "# After the GAN training is complete, you can generate and save new images for evaluation:\n",
    "num_evaluation_samples = 16\n",
    "evaluation_noise = np.random.normal(0, 1, size=(num_evaluation_samples, NOISE_DIM))\n",
    "generate_and_save_images(generator, EPOCHS, test_input=evaluation_noise, save_path='gan_evaluation')\n",
    "generator.save('gan_model.h5')\n",
    "\n",
    "# Additionally, you can perform fine-tuning by retraining the GAN with different settings or datasets.\n",
    "# You can experiment with hyperparameter tuning, generator/discriminator architecture changes, etc.\n",
    "\n",
    "# Example of fine-tuning by training for additional epochs:\n",
    "# FINE_TUNING_EPOCHS = 50\n",
    "# train_gan(generator, discriminator, gan, train_data, FINE_TUNING_EPOCHS, BATCH_SIZE, NOISE_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m num_generated_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m      7\u001b[0m generated_noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m(num_generated_samples, NOISE_DIM))\n\u001b[1;32m----> 8\u001b[0m generated_images \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(generated_noise)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Post-process the generated images to denormalize pixel values to [0, 255]\u001b[39;00m\n\u001b[0;32m     11\u001b[0m generated_images \u001b[38;5;241m=\u001b[39m ((generated_images \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m127.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "NOISE_DIM = 100\n",
    "# Step 7: Generating New Car Images\n",
    "\n",
    "# Use the generator to generate new car images.\n",
    "num_generated_samples = 100\n",
    "generated_noise = np.random.normal(0, 1, size=(num_generated_samples, NOISE_DIM))\n",
    "generated_images = generator.predict(generated_noise)\n",
    "\n",
    "# Post-process the generated images to denormalize pixel values to [0, 255]\n",
    "generated_images = ((generated_images + 1) * 127.5).astype(np.uint8)\n",
    "\n",
    "# Save the generated images\n",
    "output_folder = 'generated_cars'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for i in range(num_generated_samples):\n",
    "    img = Image.fromarray(generated_images[i])\n",
    "    img.save(f'{output_folder}/generated_car_{i:04d}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Load Trained Generator Model\n",
    "\n",
    "def load_generator_model(model_path):\n",
    "    generator = make_generator_model()\n",
    "    generator.load_weights(model_path)\n",
    "    return generator\n",
    "\n",
    "# Example usage to load the trained generator model\n",
    "saved_model_path = 'gan_model.h5'\n",
    "loaded_generator = load_generator_model(saved_model_path)\n",
    "\n",
    "# Generating new car images using the loaded generator\n",
    "num_generated_samples = 100\n",
    "generated_noise = np.random.normal(0, 1, size=(num_generated_samples, NOISE_DIM))\n",
    "generated_images = loaded_generator.predict(generated_noise)\n",
    "\n",
    "# Post-process the generated images to denormalize pixel values to [0, 255]\n",
    "generated_images = ((generated_images + 1) * 127.5).astype(np.uint8)\n",
    "\n",
    "# Save the generated images\n",
    "output_folder = 'generated_cars'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for i in range(num_generated_samples):\n",
    "    img = Image.fromarray(generated_images[i])\n",
    "    img.save(f'{output_folder}/generated_car_{i:04d}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to visualize a sample of generated images\n",
    "def visualize_generated_images(generator, noise_dim=100, num_samples=16, save_path='generated_samples.png'):\n",
    "    noise = np.random.normal(0, 1, size=(num_samples, noise_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = (generated_images + 1) * 0.5  # Rescale images to [0, 1]\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(generated_images[i])\n",
    "        plt.axis('off')\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize a sample of generated images\n",
    "visualize_generated_images(generator, noise_dim=100, num_samples=16, save_path='generated_samples.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from PIL import Image\n",
    "import os\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "# Function to preprocess images and get feature vectors using InceptionV3\n",
    "def preprocess_images(images):\n",
    "    images = preprocess_input(images)\n",
    "    return images\n",
    "\n",
    "# Function to compute FID\n",
    "def compute_fid(real_images, generated_images, batch_size=64):\n",
    "    real_images = preprocess_images(real_images)\n",
    "    generated_images = preprocess_images(generated_images)\n",
    "\n",
    "    # Load InceptionV3 model for feature extraction\n",
    "    module = hub.load(\"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\")\n",
    "    \n",
    "    # Get features for real and generated images\n",
    "    real_features = module(real_images)\n",
    "    generated_features = module(generated_images)\n",
    "\n",
    "    # Ensure the same number of features for both sets of images\n",
    "    min_num_features = min(real_features.shape[0], generated_features.shape[0])\n",
    "    real_features = real_features[:min_num_features]\n",
    "    generated_features = generated_features[:min_num_features]\n",
    "\n",
    "    # Compute the covariance matrix\n",
    "    covariance_real = np.cov(real_features, rowvar=False)\n",
    "    covariance_generated = np.cov(generated_features, rowvar=False)\n",
    "\n",
    "    # Compute the squared Frobenius norm between covariances\n",
    "    diff = real_features - generated_features\n",
    "    fid_score = np.trace(covariance_real + covariance_generated - 2 * sqrtm(np.dot(covariance_real, covariance_generated)))\n",
    "    return fid_score\n",
    "\n",
    "# Function to load and preprocess real images from a directory\n",
    "def load_real_images(directory, target_size=(128, 128)):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            image = Image.open(image_path)\n",
    "            image = image.resize(target_size)  # Resize the image to a target size\n",
    "            image = np.array(image)  # Convert image to NumPy array\n",
    "            image = image.astype(np.float32)  # Convert pixel values to float32\n",
    "            image = (image / 255.0) * 2 - 1  # Normalize pixel values to [-1, 1]\n",
    "            images.append(image)\n",
    "    return np.array(images)\n",
    "\n",
    "# Generating new car images for evaluation\n",
    "num_evaluation_samples = 1000\n",
    "evaluation_noise = np.random.normal(0, 1, size=(num_evaluation_samples, 100))\n",
    "generated_images = generator.predict(evaluation_noise)\n",
    "\n",
    "# Load and preprocess real images\n",
    "real_images_directory = \"cars\"\n",
    "real_images = load_real_images(real_images_directory)\n",
    "\n",
    "# Compute FID\n",
    "fid = compute_fid(real_images, generated_images)\n",
    "print(\"Frechet Inception Distance (FID):\", fid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detailed Report Outlining Steps and Design Choices for GAN:**\n",
    "\n",
    "**1. Introduction:**\n",
    "\n",
    "The objective of this project is to design and implement a Generative Adversarial Network (GAN) to generate new images of cars. GANs are powerful deep learning models used for generative tasks, particularly in image generation. The GAN architecture consists of two neural networks, the generator, and the discriminator, which are trained in an adversarial manner to produce realistic images.\n",
    "\n",
    "**2. Dataset:**\n",
    "\n",
    "For this project, we used a dataset containing images of cars. The dataset consists of a large collection of car images with varying viewpoints, colors, and styles. A diverse dataset is crucial to ensure the generator learns to produce a wide variety of realistic car images.\n",
    "\n",
    "**3. GAN Architecture:**\n",
    "\n",
    "The GAN architecture consists of two main components: the generator and the discriminator.\n",
    "\n",
    "- **Generator:** The generator takes random noise as input and transforms it into a generated image. It consists of a series of layers, such as dense layers and convolutional transpose layers, that gradually upsample the noise to produce a 128x128x3 image. The final activation function of the generator is typically 'tanh', which scales the pixel values between -1 and 1 to match the range of real images.\n",
    "\n",
    "- **Discriminator:** The discriminator is responsible for distinguishing between real images and generated images. It takes a 128x128x3 image as input and predicts whether the image is real or fake. The discriminator consists of convolutional layers, followed by dense layers, and the final activation function is typically 'sigmoid', which produces a probability score.\n",
    "\n",
    "**4. Hyperparameters:**\n",
    "\n",
    "Choosing appropriate hyperparameters is essential for the successful training of the GAN. Here are the hyperparameters used in this project:\n",
    "\n",
    "- `noise_dim`: The size of the noise vector, which is the input to the generator. In this project, we used `noise_dim = 100`.\n",
    "\n",
    "- `learning_rate`: The learning rate used during optimization. A typical value for the Adam optimizer is `learning_rate = 0.0002`.\n",
    "\n",
    "- `batch_size`: The number of samples in each batch used during training. We used `batch_size = 64`.\n",
    "\n",
    "- `epochs`: The number of training epochs, which determines how many times the entire dataset is passed through the GAN during training. We used `epochs = 100`.\n",
    "\n",
    "**5. Training Process:**\n",
    "\n",
    "The training process of the GAN involves iteratively updating the discriminator and the generator. Here are the main steps:\n",
    "\n",
    "- **Step 1: Define the GAN architecture:** Define the generator and the discriminator models using TensorFlow/Keras.\n",
    "\n",
    "- **Step 2: Compile the GAN model:** Compile the GAN model using the Adam optimizer and binary cross-entropy loss.\n",
    "\n",
    "- **Step 3: Load the real images:** Load and preprocess the real images from the car dataset. Ensure the images are resized to 128x128 pixels and normalized between -1 and 1.\n",
    "\n",
    "- **Step 4: Generate training data for the generator:** Generate random noise vectors as the training data for the generator. Each noise vector is of size `noise_dim`.\n",
    "\n",
    "- **Step 5: Training loop:** For a fixed number of epochs, iterate over the training data and update the discriminator and generator in an adversarial manner.\n",
    "\n",
    "- **Step 6: Adversarial Training:** Train the discriminator using real images and the generated images. The discriminator is updated with both positive (real) and negative (generated) samples. Use binary cross-entropy loss to update the discriminator.\n",
    "\n",
    "- **Step 7: Train the Generator:** Train the generator to generate more realistic images that can deceive the discriminator. Update the generator using the discriminator's feedback to minimize the binary cross-entropy loss.\n",
    "\n",
    "- **Step 8: Evaluate the generator:** After training, evaluate the generator by generating new images using random noise vectors. Save and visualize the generated images to assess the quality of the model.\n",
    "\n",
    "**6. Rationale Behind Design Choices:**\n",
    "\n",
    "- **Architecture Choice:** We chose a simple yet effective architecture for the generator and discriminator. The generator architecture gradually upsamples the noise to produce realistic 128x128 images, while the discriminator has a structure to effectively classify real and generated images.\n",
    "\n",
    "- **Activation Functions:** We used 'tanh' as the activation function for the generator's final layer to ensure pixel values are within the range [-1, 1]. For the discriminator, 'sigmoid' activation provides probability scores for distinguishing real and fake images.\n",
    "\n",
    "- **Hyperparameters:** We set the hyperparameters based on common practices and experimentation. The learning rate, batch size, and number of epochs were tuned to achieve a balance between training time and the quality of generated images.\n",
    "\n",
    "- **Training Process:** The adversarial training process is crucial for GANs. By iteratively updating the generator and discriminator, the GAN converges to a point where the generator produces realistic images, and the discriminator is unable to distinguish between real and generated images.\n",
    "\n",
    "**7. Conclusion:**\n",
    "\n",
    "In conclusion, we successfully designed and implemented a GAN to generate new images of cars. The GAN was trained using a dataset of real car images and random noise vectors as input to the generator. The GAN learned to generate realistic images that resembled the distribution of the real dataset. The choice of architecture and hyperparameters played a crucial role in the GAN's performance. The generated images can be used for various applications, such as data augmentation or creating synthetic datasets for training other machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying GAN to cloud based service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploying a GAN to a cloud-based service involves setting up a server or cloud instance that can host the GAN model and serve requests for generating new images. Here's a brief explanation of the steps to deploy a GAN to a cloud-based service:\n",
    "\n",
    "**1. Choose a Cloud Service Provider:**\n",
    "Select a cloud service provider that suits your requirements, such as Amazon Web Services (AWS), Google Cloud Platform (GCP), Microsoft Azure, or others. Consider factors like cost, available resources, and ease of deployment when making your choice.\n",
    "\n",
    "**2. Set Up a Virtual Machine (VM) or Container:**\n",
    "Create a virtual machine (VM) or container to host your GAN model. VMs provide full flexibility, while containers offer a more lightweight and portable solution.\n",
    "\n",
    "**3. Install Dependencies:**\n",
    "Install all the necessary dependencies and libraries required to run the GAN model on the cloud instance. This includes TensorFlow/Keras, any specific libraries used in the GAN code, and the required GPU drivers (if using GPUs for accelerated computation).\n",
    "\n",
    "**4. Upload GAN Model and Weights:**\n",
    "Upload the trained GAN model and its weights to the cloud instance. This can be done by copying the model files from your local machine to the cloud instance.\n",
    "\n",
    "**5. Expose an API Endpoint:**\n",
    "Set up an API endpoint on the cloud instance that can receive requests for generating new images. This API endpoint will accept input (e.g., noise vectors) and return the generated images.\n",
    "\n",
    "**6. Create API Server:**\n",
    "Build a simple web server (using Flask, Django, FastAPI, etc.) that listens for incoming requests on the API endpoint. This server will load the GAN model and use it to generate new images based on the input received.\n",
    "\n",
    "**7. Implement Generation Logic:**\n",
    "In the web server, implement the logic to process the input (e.g., noise vectors) and generate images using the loaded GAN model. Make sure to preprocess the input and post-process the output images as needed.\n",
    "\n",
    "**8. Handle Multiple Requests:**\n",
    "Ensure that the web server can handle multiple requests simultaneously. Consider using a queue system or asynchronous processing to handle multiple requests efficiently.\n",
    "\n",
    "**9. Deploy the Server:**\n",
    "Deploy the web server on the cloud instance and make it accessible via a public IP or domain. This is usually done using the cloud service provider's interface or command-line tools.\n",
    "\n",
    "**10. Test and Monitor:**\n",
    "Test the deployed GAN service by sending requests and verifying that it generates images as expected. Monitor the server's performance, resource usage, and any errors or exceptions to ensure smooth operation.\n",
    "\n",
    "**11. Scale as Needed:**\n",
    "Depending on the demand, scale up the cloud instance or use load balancers to distribute requests across multiple instances for improved performance and reliability.\n",
    "\n",
    "**12. API Documentation:**\n",
    "Optionally, create documentation for your GAN API, specifying the input format, expected responses, and any usage guidelines.\n",
    "\n",
    "By following these steps, you can deploy your GAN to a cloud-based service, allowing others to access and use your model for generating new images via simple API requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
